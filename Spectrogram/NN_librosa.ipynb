{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LANL Earthquakes Experiment\n",
    "# Spectrogram Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook continues from the point where Spectrogram_librosa.ipynb created a directory of spectrograms made using librosa library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO - external:\n",
    "- look for regression that returns distribution rather than point estimator?\n",
    "- go on to transformers.\n",
    "\n",
    "TODO - NN:\n",
    "- track errors (both train & valid) in multi-level training process (use learn.recorder.losses / val_losses?).\n",
    "- made 81.6% classification error with mixup. 81.7% without mixup and becoming worse quicky (after the 2nd iteration!).\n",
    "- go over regression NN in fastai course in lesson 3 notebook.\n",
    "\n",
    "- if looks good - go on to resnet50.\n",
    "- add external (non-raw-signal) features.\n",
    "   - find a way to extract the output of 1 or 2 layers before the final output (instead of the final output itself).\n",
    "   - pass to Zahar a way to generate this \"pre-output\" as features for his model.\n",
    "   - if possible - also pass to Zahar a way to train a network to generate these features (to allow features training with the same CV).\n",
    "   - an alternative to 2 sequential models would be a single model with additional input in advanced layers - read about custom itemlist in fastai.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.stats as stats\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.polynomial.polynomial import polyfit\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "import pickle as pkl\n",
    "from time import time\n",
    "from tqdm import tqdm, tnrange, tqdm_notebook\n",
    "from pprint import pprint\n",
    "import os, sys\n",
    "from warnings import warn\n",
    "import itertools\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "from fastai.vision import *\n",
    "from fastai.metrics import error_rate#, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0 = none; 1 = load; 2 = run.\n",
    "RUN_CV = 1\n",
    "RUN_CLASSIFICATION = 2\n",
    "RUN_REGRESSION = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation\n",
    "\n",
    "A validation fold consists of 20% of the segments, in batches of 40 sequential segments (after x6 augmentation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Path consts\n",
    "BASE = Path('../Data')\n",
    "TRAIN = BASE/'train_spec2'\n",
    "\n",
    "# NN consts\n",
    "BS = 32 # 64 already causes OOM error in the regression\n",
    "MIXUP = TRUE\n",
    "\n",
    "# Data consts\n",
    "SIZE = (187,147)\n",
    "meta = pd.read_csv(TRAIN/'train_spec_meta.csv')\n",
    "n_hops = len(meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_folds(meta, K_FOLDS=None, COLORS = ('k','b','r','g','y')):\n",
    "    if K_FOLDS is None:\n",
    "        K_FOLDS = len(np.unique(meta.fold))\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    for k in range(K_FOLDS):\n",
    "        plt.plot(np.argwhere(meta.fold==k), meta.loc[meta.fold==k,'time'], COLORS[k]+'.', label=k)\n",
    "    plt.xlabel('Segment\\n(with x6 overlapping)')\n",
    "    plt.ylabel('TTF')\n",
    "    plt.title('Train Data Folding')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.figure(figsize=(10,6))\n",
    "    for k in range(K_FOLDS):\n",
    "        sns.distplot(meta.loc[meta.fold==k,'time'], color=COLORS[k], hist=False, label=k)\n",
    "    plt.xlabel('TTF')\n",
    "    plt.title('Train Data Folding')\n",
    "    plt.legend()\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation configuration\n",
    "validation_type = 'load' if RUN_CV<2 else 'CV'\n",
    "valid_rate = 0.2\n",
    "K_FOLDS = int(1/valid_rate)\n",
    "batch_size = 40\n",
    "np.random.seed(0)\n",
    "\n",
    "\n",
    "# Create validation set\n",
    "if validation_type == 'random':\n",
    "    n_batches = n_hops // batch_size\n",
    "    n_val_batches = int(valid_rate * n_batches)\n",
    "    validation_batches = np.random.choice(range(n_batches), n_val_batches, replace=False)\n",
    "    val_ids = np.concatenate([np.arange(i0*batch_size,(i0+1)*batch_size,dtype=int) for i0 in validation_batches])\n",
    "    \n",
    "elif validation_type == 'sequential':\n",
    "    val_ids = np.array(range(int((1-valid_rate)*n_hops),n_hops))\n",
    "    \n",
    "elif validation_type == 'CV':\n",
    "    meta['fold'] = 0\n",
    "    hops = meta.loc[np.arange(0, n_hops-batch_size, batch_size)]\n",
    "    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True)\n",
    "    for k, (train_index, valid_index) in enumerate(skf.split(hops['filename'], hops['class'])):\n",
    "        val_ids = np.concatenate([np.arange(batch_size*i,batch_size*(i+1)) for i in valid_index])\n",
    "        meta.loc[val_ids, 'fold'] = k\n",
    "    meta.to_csv(TRAIN/'train_spec_meta.csv', index=False)\n",
    "\n",
    "\n",
    "# Summary & save/load\n",
    "if validation_type == 'load':\n",
    "    # Note: all these variables are actually useful only for a single fold.\n",
    "    # for a full CV, use instead the column 'fold' in meta.\n",
    "    val_ids, val_set, train_mean, train_std = pkl.load(open(TRAIN/'validation_set.pkl','rb'))\n",
    "else:\n",
    "    val_set = set(meta.iloc[val_ids]['filename'])\n",
    "    train_mean = np.mean([m for i,m in enumerate(meta['mean']) if i not in val_ids])\n",
    "    train_std = np.sqrt(np.mean([m for i,m in enumerate(meta['var']) if i not in val_ids])) # not really std...\n",
    "    pkl.dump((val_ids,val_set,train_mean,train_std), open(TRAIN/'validation_set.pkl','wb'))\n",
    "\n",
    "if 'fold' in meta.columns:\n",
    "    plot_folds(meta)\n",
    "    \n",
    "(val_ids[:5], train_mean, train_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#meta = meta.head(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_data(meta, fold, verbose=1):\n",
    "    validation_set = {nm: k for nm,k in zip(meta.filename,meta.fold)}\n",
    "    \n",
    "    data = ImageDataBunch.create_from_ll(\n",
    "        (ImageList.from_df(meta[['filename','class']], path=TRAIN, folder=None, suffix='', cols=0)\n",
    "                    .split_by_valid_func(lambda nm: validation_set[os.path.basename(nm)]==fold)\n",
    "                    .label_from_df(label_delim=None, cols=1)),\n",
    "        ds_tfms=[], size=SIZE, bs=BS\n",
    "    ).normalize()\n",
    "    # Note: normalize() uses by default self.stats = self.batch_stats() = [torch.mean,torch.std].\n",
    "    # This should be good since we have very weird values and we wish to normalize them to nore conventional values.\n",
    "    # RESNET34 kind of assumes a more specific input distribution (imagenet_stats),\n",
    "    # but as far as we don't have convergence issues, we'll stick to this.\n",
    "    \n",
    "    classification_data_info(data, verbose)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def classification_data_info(data, verbose):\n",
    "    if verbose >= 1:\n",
    "        print(data)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.distplot(classes2times(data.label_list.train.y.classes), color='b', hist=False, label='Train')\n",
    "        sns.distplot(classes2times(data.label_list.valid.y.classes), color='r', hist=False, label='Valid')\n",
    "        plt.xlabel('TTF [s]')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    if verbose >= 2:\n",
    "        data.show_batch(rows=3, figsize=(9,6))\n",
    "    \n",
    "def classes2times(cls):\n",
    "    return np.array([class2time(c) for c in cls])\n",
    "\n",
    "def class2time(c):\n",
    "    t = (int(c[:2])+int(c[-2:]))/2\n",
    "    return min(t,13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_learn(data, lr_range=(3e-5,3e-4), cycles=(4,4), mixup=True,\n",
    "                         save_label=None, load=False, predict=True, find_lr=True):\n",
    "    # initialize\n",
    "    learn = cnn_learner(data, models.resnet34, metrics=error_rate)\n",
    "    if mixup:\n",
    "        learn.mixup()\n",
    "    \n",
    "    # train\n",
    "    if load:\n",
    "        if load == 'freezed':\n",
    "            learn.load(f'model_spec_class_resnet34_freezed_mxp{mixup:d}_'+save_label)\n",
    "        elif load == 'unfreezed':\n",
    "            learn.load(f'model_spec_class_resnet34_unfreezed_mxp{mixup:d}_'+save_label)\n",
    "        else:\n",
    "            raise ValueError(\"load must be either 'freezed' or 'unfreezed'.\")\n",
    "    \n",
    "    else:\n",
    "        # TODO track training errors (on both train & validation sets)\n",
    "        if cycles[0] > 0:\n",
    "            learn.fit_one_cycle(cycles[0])\n",
    "            if save_label is not None:\n",
    "                learn.save(f'model_spec_class_resnet34_freezed_mxp{mixup:d}_'+save_label)\n",
    "\n",
    "        if find_lr:\n",
    "            learn.lr_find()\n",
    "            learn.recorder.plot()\n",
    "\n",
    "        if cycles[1] > 0:\n",
    "            learn.unfreeze()\n",
    "            learn.fit_one_cycle(cycles[1], max_lr=slice(lr_range[0],lr_range[1]))\n",
    "            if save_label is not None:\n",
    "                learn.save(f'model_spec_class_resnet34_unfreezed_mxp{mixup:d}_'+save_label)\n",
    "                \n",
    "    # predict\n",
    "    if predict:\n",
    "        yv = np.array([str(learn.predict(x)[0]) for x in tqdm_notebook(learn.data.label_list.valid.x)], dtype='S8')\n",
    "    else:\n",
    "        yv = None\n",
    "    \n",
    "    return learn, yv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classification_interpretation(learn=None, interp=None, detailed=2):\n",
    "    if interp is None:\n",
    "        interp = ClassificationInterpretation.from_learner(learn)\n",
    "    \n",
    "    print('MAE:\\t{0:.5f}'.format(confusion2mae(interp.confusion_matrix())))\n",
    "    \n",
    "    if detailed >= 1:\n",
    "        interp.plot_confusion_matrix(figsize=(12,12), dpi=60)\n",
    "        \n",
    "    if detailed >= 2:\n",
    "        interp.plot_top_losses(9, figsize=(15,11), largest=False, heatmap = True)\n",
    "        interp.plot_top_losses(9, figsize=(15,11), largest=False, heatmap = False)\n",
    "        interp.plot_top_losses(9, figsize=(15,11), largest=True,  heatmap = False)\n",
    "        interp.plot_top_losses(9, figsize=(15,11), largest=True,  heatmap = True)\n",
    "        \n",
    "    return interp\n",
    "\n",
    "def confusion2mae(M, class_limits=np.array([0,1,2,3,4,5,6,7,8,10,12,16])):\n",
    "    class_centers = (class_limits[1:]+class_limits[:-1])/2\n",
    "    class_lengths = np.diff(class_limits)\n",
    "    tot_err = 0\n",
    "    n = 0\n",
    "    for i in range(M.shape[0]):\n",
    "        for j in range(M.shape[1]):\n",
    "            n += M[i,j]\n",
    "            tot_err += M[i,j] * (np.abs(class_centers[i]-class_centers[j]) if i!=j else class_lengths[i]/4)\n",
    "    return tot_err / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def analyze_errors(y0, y, tit, folds=None,\n",
    "                   class_limits=np.array([-99,0,1,2,3,4,5,6,7,8,10,12,14,99]), COLORS=('k','b','r','g','y')):\n",
    "    tit = '['+tit+']'\n",
    "    \n",
    "    print('Sizes:\\t', y0.shape, y.shape)\n",
    "    errs = y - y0\n",
    "    print('MAE:\\t', np.abs(errs).mean())\n",
    "    \n",
    "    if folds is not None:\n",
    "        fig, axs = plt.subplots(1,2, figsize=(15,8))\n",
    "        for k in range(len(np.unique(folds))):\n",
    "            sns.distplot(errors[folds==k], color=COLORS[k], hist=False, label=k, ax=axs[0])\n",
    "        axs[0].set_xlabel('Predicted TTF')\n",
    "        axs[0].set_title(tit+' Predictions per Folder')\n",
    "        axs[0].legend()\n",
    "        axs[0].grid()\n",
    "        sns.boxplot(x='Folder', y='Absolute Error [s]', data=pd.DataFrame({'Fold':folds, 'Absolute Error [s]':np.abs(errs)}),\n",
    "                    showmeans=True, ax=axs[1])\n",
    "        axs[1].set_title(tit)\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2, figsize=(15,4))\n",
    "    axs[0].plot(y, color='r', label='Model Predictions')\n",
    "    axs[0].plot(y0, color='g', label='Ground Truth')\n",
    "    axs[0].set_ylabel('TTF [s]')\n",
    "    axs[0].set_title(tit)\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()\n",
    "    axs[1].plot(errs)\n",
    "    axs[1].set_ylabel('Error [s]')\n",
    "    axs[1].set_title(tit)\n",
    "    axs[1].grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig, axs = plt.subplots(1,2, figsize=(15,4))\n",
    "    sns.distplot(y, color='r', ax=axs[0], label='Model Predictions')\n",
    "    sns.distplot(y0, color='g', ax=axs[0], label='Ground Truth')\n",
    "    axs[0].set_title(tit)\n",
    "    axs[0].set_xlabel('TTF [s]')\n",
    "    axs[0].grid()\n",
    "    axs[0].legend()\n",
    "    sns.distplot(errs, ax=axs[1])\n",
    "    axs[1].set_title(tit)\n",
    "    axs[1].set_xlabel('Error [s]')\n",
    "    axs[1].grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    fig, axs = plt.subplots(1,3, figsize=(15,4))\n",
    "    b, a = polyfit(y0, y, 1)\n",
    "    axs[0].plot(y0, a*y0+b, 'r-')\n",
    "    axs[0].plot(y0, y, 'b,')\n",
    "    axs[0].set_title(tit)\n",
    "    axs[0].set_xlabel('True TTF')\n",
    "    axs[0].set_ylabel('Predicted TTF')\n",
    "    axs[0].grid()\n",
    "    b, a = polyfit(y0, errs, 1)\n",
    "    axs[1].plot(y0, a*y0+b, 'r-')\n",
    "    axs[1].plot(y0, errs, 'b,')\n",
    "    axs[1].set_title(tit)\n",
    "    axs[1].set_xlabel('True TTF')\n",
    "    axs[1].set_ylabel('Error')\n",
    "    axs[1].grid()\n",
    "    b, a = polyfit(y, errs, 1)\n",
    "    axs[2].plot(y, a*y+b, 'r-')\n",
    "    axs[2].plot(y, errs, 'b,')\n",
    "    axs[2].set_title(tit)\n",
    "    axs[2].set_xlabel('Predicted TTF')\n",
    "    axs[2].set_ylabel('Error')\n",
    "    axs[2].grid()\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    order = [f'{a:d}-{b:d}' for a,b in zip(class_limits[:-1],class_limits[1:])]\n",
    "    cls0 = [[f'{a:d}-{b:d}' for a,b in zip(class_limits[:-1],class_limits[1:]) if a<=t<b][0] for t in y0]\n",
    "    cls = [[f'{a:d}-{b:d}' for a,b in zip(class_limits[:-1],class_limits[1:]) if a<=t<b][0] for t in y]\n",
    "    df = pd.DataFrame({'True TTF':cls0, 'Predicted TTF':cls, 'Predicted TTF numeric':y, 'Error':errs})\n",
    "    \n",
    "    # consider adding number of observations in annotation:\n",
    "    # https://python-graph-gallery.com/58-show-number-of-observation-on-violinplot/\n",
    "    fig, axs = plt.subplots(3,1, figsize=(15,12))\n",
    "    sns.violinplot(x='True TTF', y='Predicted TTF numeric', data=df, order=order, scale='width', showmeans=True, ax=axs[0])\n",
    "    axs[0].set_ylabel('Predicted TTF')\n",
    "    axs[0].set_title(tit)\n",
    "    axs[0].grid()\n",
    "    sns.violinplot(x='True TTF', y='Error', data=df, order=order, scale='width', showmeans=True, ax=axs[1])\n",
    "    axs[1].set_title(tit)\n",
    "    axs[1].grid()\n",
    "    sns.violinplot(x='Predicted TTF', y='Error', data=df, order=order, scale='width', showmeans=True, ax=axs[2])\n",
    "    axs[2].set_title(tit)\n",
    "    axs[2].grid()\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_CLASSIFICATION:\n",
    "\n",
    "    LOAD_ONLY = 'unfreezed' if RUN_CLASSIFICATION==1 else False\n",
    "\n",
    "    K = len(np.unique(meta.fold))\n",
    "    assert(K == K_FOLDS), 'Bad number of folders.'\n",
    "    print(f'Number of folders:\\t{K:d}')\n",
    "    n_classes = len(np.unique(meta['class']))\n",
    "    print(f'Number of classes:\\t{n_classes:d}')\n",
    "\n",
    "    YV0_C = meta['class']\n",
    "    YV_C = np.zeros(len(meta), dtype='S8')\n",
    "    confusions = [np.zeros((n_classes, n_classes), dtype=int)]\n",
    "    for k in range(K):\n",
    "        data_class = classification_data(meta, k, verbose = (2 if k==0 else 0))\n",
    "        learn_class, yv_class = classification_learn(data_class, cycles=(4,3), mixup=MIXUP, save_label=f'{k:d}', load=LOAD_ONLY)\n",
    "        YV_C[meta.fold==k] = yv_class\n",
    "        try:\n",
    "            interp_class = classification_interpretation(learn_class, detailed = (2 if k==0 else 0))\n",
    "            confusions += [interp_class.confusion_matrix()]\n",
    "        except:\n",
    "            warn('Classification interpretation failed.')\n",
    "\n",
    "    pkl.dump((YV_C, confusions), open(TRAIN/'classification_results.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if RUN_CLASSIFICATION:\n",
    "    analyze_errors(meta.time, classes2times(YV_C), 'Classification vs. Continuous Labels: Validation')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression\n",
    "\n",
    "Note: range of MAE should be between 2.0 (excellent) and 2.2 (quite bad), for CV that takes groups of 20 x3-augmented-segments (i.e. 7 original segments, or 1.05M samples) as homogeneous buckets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_data(meta, fold, verbose=1):\n",
    "    validation_set = {nm: k for nm,k in zip(meta.filename,meta.fold)}\n",
    "    \n",
    "    data = (PointsItemList.from_df(meta[['filename','time']], TRAIN)\n",
    "            .split_by_valid_func(lambda nm: validation_set[os.path.basename(nm)]==fold)\n",
    "            .label_from_df(cols='time', label_cls=FloatList)\n",
    "            .transform(size=SIZE)\n",
    "            .databunch()).normalize()\n",
    "    data.batch_size = BS\n",
    "    # Note: normalize() uses by default self.stats = self.batch_stats() = [torch.mean,torch.std].\n",
    "    # This should be good since we have very weird values and we wish to normalize them to nore conventional values.\n",
    "    # RESNET34 kind of assumes a more specific input distribution (imagenet_stats),\n",
    "    # but as far as we don't have convergence issues, we'll stick to this.\n",
    "    \n",
    "    regression_data_info(data, verbose)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def regression_data_info(data, verbose):\n",
    "    if verbose >= 1:\n",
    "        print(data)\n",
    "        plt.figure(figsize=(8,5))\n",
    "        sns.distplot(data.label_list.train.y.items, color='b', hist=True, label='Train')\n",
    "        sns.distplot(data.label_list.valid.y.items, color='r', hist=True, label='Valid')\n",
    "        plt.xlabel('TTF')\n",
    "        plt.legend()\n",
    "        plt.grid()\n",
    "    if verbose >= 2:\n",
    "        data.show_batch(rows=3, figsize=(9,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def regression_learn(data, lr_range=(3e-5,3e-4), cycles=(4,2), mixup=True,\n",
    "                     save_label=None, load=False, predict=True, find_lr=True):\n",
    "    \n",
    "    # initialize\n",
    "    learn = cnn_learner(data, models.resnet34, loss_func=mean_absolute_error, metrics=mean_absolute_error)\n",
    "    learn.loss = F.l1_loss\n",
    "    if mixup:\n",
    "        learn.mixup()\n",
    "    \n",
    "    # train\n",
    "    if load:\n",
    "        if load == 'freezed':\n",
    "            learn.load(f'model_spec_reg_resnet34_freezed_mxp{mixup:d}_'+save_label)\n",
    "        elif load == 'unfreezed':\n",
    "            learn.load(f'model_spec_reg_resnet34_unfreezed_mxp{mixup:d}_'+save_label)\n",
    "        else:\n",
    "            raise ValueError(\"load must be either 'freezed' or 'unfreezed'.\")\n",
    "        \n",
    "    else:\n",
    "        # TODO track training errors (on both train & validation sets)\n",
    "        if cycles[0] > 0:\n",
    "            learn.fit_one_cycle(cycles[0])\n",
    "            if save_label is not None:\n",
    "                learn.save(f'model_spec_reg_resnet34_freezed_mxp{mixup:d}_'+save_label)\n",
    "\n",
    "        if find_lr:\n",
    "            learn.lr_find()\n",
    "            learn.recorder.plot()\n",
    "\n",
    "        if cycles[1] > 0:\n",
    "            learn.unfreeze()\n",
    "            learn.fit_one_cycle(cycles[1], max_lr=slice(lr_range[0],lr_range[1]))\n",
    "            if save_label is not None:\n",
    "                learn.save(f'model_spec_reg_resnet34_unfreezed_mxp{mixup:d}_'+save_label)\n",
    "    \n",
    "    # predict\n",
    "    if predict:\n",
    "        out = learn.get_preds(learn.data)\n",
    "        yt0 = out[1]\n",
    "        yt = np.reshape(out[0], (out[0].shape[0],))\n",
    "        yv0 = learn.data.label_list.valid.y.items\n",
    "        yv = np.array([learn.predict(x)[0].data[0] for x in tqdm_notebook(learn.data.label_list.valid.x)])\n",
    "        # ridiculously can't find any better way to get validation predictions. maybe try generalizing from this:\n",
    "        # np.array(model.get_preds(ds_type=DatasetType.Valid)[0])\n",
    "    else:\n",
    "        yt0, yt, yv0, yv = (None for _ in range(4))\n",
    "    \n",
    "    return learn, yt0, yt, yv0, yv\n",
    "\n",
    "def mean_absolute_error(pred:Tensor, targ:Tensor, reduction=None)->Rank0Tensor:\n",
    "    \"Mean absolute error between `pred` and `targ`.\"\n",
    "    \"\"\" A copied version of FastAI function with additional 'reduction' argument,\n",
    "    in sake of compatibility with up-to-date Pytorch. \"\"\"\n",
    "    pred,targ = flatten_check(pred,targ)\n",
    "    errs = torch.abs(targ.float() - pred.float())\n",
    "    if reduction is None or reduction=='mean':\n",
    "        return errs.mean()\n",
    "    if reduction=='none':\n",
    "        return errs\n",
    "    return errs.sum()\n",
    "\n",
    "# class L1LossFlat(nn.L1Loss):\n",
    "#     '''Mean Absolute Error Loss; seems that it is not necessary anymore, and F.l1_loss does fine.'''\n",
    "#     def forward(self, input:Tensor, target:Tensor) -> Rank0Tensor:\n",
    "#         return super().forward(input.view(-1), target.view(-1))\n",
    "# learn.loss = L1LossFlat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if RUN_REGRESSION:\n",
    "\n",
    "    LOAD_ONLY = 'unfreezed' if RUN_REGRESSION==1 else False\n",
    "\n",
    "    K = len(np.unique(meta.fold))\n",
    "    print(f'Number of folders:\\t{K:d}')\n",
    "\n",
    "    YV0 = meta.time\n",
    "    YV = np.zeros(len(meta))\n",
    "    for k in range(K):\n",
    "        data = regression_data(meta, k, verbose = (2 if k==0 else 0))\n",
    "        learn, yt0, yt, yv0, yv = regression_learn(data, cycles=(4,2), mixup=MIXUP, save_label=f'{k:d}', load=LOAD_ONLY)\n",
    "        YV[meta.fold==k] = yv\n",
    "    \n",
    "    YV_crop = np.maximum(np.minimum(YV, 16.5), 0)\n",
    "\n",
    "    pkl.dump((YV0, YV, YV_crop), open(TRAIN/'regression_results.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RUN_REGRESSION:\n",
    "    analyze_errors(YV0, YV_crop, 'Regression: Validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_vs_reg(y0, yr, yc, class_limits=np.array([-99,0,1,2,3,4,5,6,7,8,10,12,14,99])):\n",
    "    \n",
    "    yc0, yc = yc, classes2times(yc)\n",
    "    errs_class = yc - y0\n",
    "    errs_reg = yr - y0\n",
    "    print('Samples:\\t', y0.shape)\n",
    "    print('MAE - Classification:\\t', np.mean(np.abs(errs_class)))\n",
    "    print('MAE - Regression:\\t', np.mean(np.abs(errs_reg)))\n",
    "    \n",
    "    order = [f'{a:d}-{b:d}' for a,b in zip(class_limits[:-1],class_limits[1:])]\n",
    "    cls0 = [[f'{a:d}-{b:d}' for a,b in zip(class_limits[:-1],class_limits[1:]) if a<=t<b][0] for t in y0]\n",
    "    #cls = [[f'{a:d}-{b:d}' for a,b in zip(class_limits[:-1],class_limits[1:]) if a<=t<b][0] for t in y]\n",
    "    df = pd.DataFrame({\n",
    "        'True TTF': cls0+cls0,\n",
    "        'Model': len(cls0)*['Classification'] + len(cls0)*['Regression'],\n",
    "        'Error': np.concatenate((errs_class, errs_reg)),\n",
    "        'Absolute Error': np.concatenate((np.abs(errs_class), np.abs(errs_reg)))\n",
    "    })\n",
    "    \n",
    "    fig, axs = plt.subplots(2,1, figsize=(15,10))\n",
    "    sns.violinplot(ax=axs[0], x=\"True TTF\", y=\"Error\", hue=\"Model\", data=df,\n",
    "                   palette=\"muted\", split=True, scale=\"width\", inner=\"quartile\", showmeans=True)\n",
    "    axs[0].grid()\n",
    "    sns.violinplot(ax=axs[1], x=\"True TTF\", y=\"Absolute Error\", hue=\"Model\", data=df,\n",
    "                   palette=\"muted\", split=True, scale=\"width\", inner=\"quartile\", showmeans=True)\n",
    "    axs[1].grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if RUN_CLASSIFICATION and RUN_REGRESSION:\n",
    "    class_vs_reg(YV0, YV_crop, YV_C)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai v1",
   "language": "python",
   "name": "fastai_v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
